# 1. ìƒˆ íŒŒì¼ ìƒì„±

import torch
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import argparse
import numpy as np
import json
from datetime import datetime

def main(exp_dir=None):
    from src.config import Config
    from src.transforms import get_val_transform
    from src.dataset import DocumentDataset
    from src.model import get_model
    from torch.utils.data import DataLoader

    cfg = Config()
    device = cfg.DEVICE

    if exp_dir is None:
        exp_dirs = sorted(Path('experiments').glob('exp_*'))
        if not exp_dirs:
            raise ValueError("ì‹¤í—˜ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!")
        exp_dir = exp_dirs[-1]
        print(f"ğŸ“ ê°€ì¥ ìµœê·¼ ì‹¤í—˜ ì‚¬ìš©: {exp_dir}")
    else:
        exp_dir = Path(exp_dir)

    # ì‹¤í—˜ì˜ ì„¤ì • ë¡œë“œ (results.jsonì—ì„œ)
    results_files = list(exp_dir.glob('results_fold*.json'))
    avg_val_f1 = None

    if results_files:
        # ëª¨ë“  foldì˜ ê²°ê³¼ ë¡œë“œ
        fold_results = []
        for result_file in sorted(results_files):
            with open(result_file, 'r') as f:
                fold_data = json.load(f)
                fold_results.append(fold_data)

        exp_config = fold_results[0]['config']
        model_name = exp_config['model_name']
        image_size = exp_config['image_size']
        dropout = exp_config['dropout']

        # í‰ê·  val F1 ê³„ì‚°
        val_f1_scores = [fold['best_results']['val_f1'] for fold in fold_results]
        avg_val_f1 = np.mean(val_f1_scores)

        print(f"ğŸ“‹ ì‹¤í—˜ ì„¤ì • ë¡œë“œ: {model_name}, img_size={image_size}, dropout={dropout}")
        print(f"ğŸ“Š í‰ê·  Validation F1: {avg_val_f1:.4f}")
    else:
        # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ í˜„ì¬ config ì‚¬ìš©
        model_name = cfg.MODEL_NAME
        image_size = cfg.IMAGE_SIZE
        dropout = cfg.DROPOUT
        print(f"âš ï¸  ì‹¤í—˜ ì„¤ì • ì—†ìŒ - í˜„ì¬ config ì‚¬ìš©")
    
    # K-Fold ëª¨ë¸ í™•ì¸ (ë‘ ê°€ì§€ êµ¬ì¡° ì§€ì›)
    folds_dir = exp_dir / 'folds'
    fold_models = list(exp_dir.glob('best_model_fold*.pth'))

    is_kfold = folds_dir.exists() or len(fold_models) > 0

    print("="*70)
    print(f"ğŸ”® ì¶”ë¡  ì‹œì‘")
    print(f"   ì‹¤í—˜: {exp_dir.name}")
    if is_kfold:
        if folds_dir.exists():
            fold_dirs = sorted(folds_dir.glob('fold*'))
            print(f"   ëª¨ë“œ: K-Fold ì•™ìƒë¸” ({len(fold_dirs)} Folds)")
        else:
            print(f"   ëª¨ë“œ: K-Fold ì•™ìƒë¸” ({len(fold_models)} Folds)")
    else:
        print(f"   ëª¨ë“œ: Single Model")
    print("="*70)
    print()

    print("ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ...")
    test_df = pd.read_csv(f'{cfg.DATA_DIR}/sample_submission.csv')
    print(f"  Test: {len(test_df)}ê°œ\n")

    transform = get_val_transform(image_size)
    test_dataset = DocumentDataset(test_df, cfg.TEST_DIR, transform)

    test_loader = DataLoader(
        test_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=False,
        num_workers=0
    )

    if is_kfold:
        all_predictions = []

        # folds/ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë˜ëŠ” ì§ì ‘ fold ëª¨ë¸ íŒŒì¼ ì§€ì›
        if folds_dir.exists():
            fold_dirs = sorted(folds_dir.glob('fold*'))
            model_paths = [fold_dir / 'model.pth' for fold_dir in fold_dirs]
        else:
            model_paths = sorted(exp_dir.glob('best_model_fold*.pth'))

        for fold_idx, model_path in enumerate(model_paths):
            print(f"ğŸ“¦ Fold {fold_idx+1}/{len(model_paths)} ëª¨ë¸ ë¡œë“œ...")
            print(f"   {model_path.name}")

            model = get_model(model_name, cfg.NUM_CLASSES, dropout)
            model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))
            model = model.to(device)
            model.eval()

            print(f"ğŸ”® Fold {fold_idx+1} ì¶”ë¡  ì¤‘...")
            fold_preds = []

            with torch.no_grad():
                for batch in tqdm(test_loader, desc=f'Fold {fold_idx+1}', leave=False):
                    if isinstance(batch, (tuple, list)):
                        images = batch[0]
                    else:
                        images = batch

                    images = images.to(device)
                    outputs = model(images)
                    probs = torch.softmax(outputs, dim=1)
                    fold_preds.append(probs.cpu().numpy())

            fold_preds = np.concatenate(fold_preds, axis=0)
            all_predictions.append(fold_preds)

            print(f"âœ… Fold {fold_idx+1} ì™„ë£Œ\n")

        print("ğŸ”€ ì•™ìƒë¸” ì¤‘...")
        ensemble_probs = np.mean(all_predictions, axis=0)
        predictions = np.argmax(ensemble_probs, axis=1).tolist()
        
    else:
        model_path = exp_dir / 'best_model.pth'
        if not model_path.exists():
            raise ValueError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")

        print("ğŸ“¦ ëª¨ë¸ ë¡œë“œ...")
        model = get_model(model_name, cfg.NUM_CLASSES, dropout)
        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))
        model = model.to(device)
        model.eval()
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")

        print("ğŸ”® ì¶”ë¡  ì¤‘...")
        predictions = []

        with torch.no_grad():
            for batch in tqdm(test_loader, desc='Inference'):
                if isinstance(batch, (tuple, list)):
                    images = batch[0]
                else:
                    images = batch
                
                images = images.to(device)
                outputs = model(images)
                preds = outputs.argmax(dim=1)
                predictions.extend(preds.cpu().numpy().tolist())

    test_df['target'] = predictions

    # ì œì¶œ íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ_ì‹œê°„_ëª¨ë¸ëª…_valF1.csv)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename_parts = [timestamp]

    if is_kfold:
        filename_parts.append(f"ensemble_{len(model_paths)}fold")
    else:
        filename_parts.append("single")

    filename_parts.append(model_name)

    if avg_val_f1 is not None:
        filename_parts.append(f"valF1_{avg_val_f1:.4f}")

    submission_filename = "_".join(filename_parts) + ".csv"
    submission_path = exp_dir / submission_filename
    test_df.to_csv(submission_path, index=False)

    print("\nğŸ“Š ì˜ˆì¸¡ ë¶„í¬:")
    print(test_df['target'].value_counts().sort_index())

    print("\n" + "="*70)
    print(f"âœ… ì œì¶œ íŒŒì¼: {submission_path}")
    print("="*70)

    print("\nğŸ” ìµœì¢… ê²€ì¦:")
    sample = pd.read_csv(f'{cfg.DATA_DIR}/sample_submission.csv')

    checks = {
        'Shape ì¼ì¹˜': test_df.shape == sample.shape,
        'ID ìˆœì„œ ì¼ì¹˜': (test_df['ID'] == sample['ID']).all(),
        'Target íƒ€ì…': test_df['target'].dtype in ['int64', 'int32'],
        'Target ë²”ìœ„': (test_df['target'].min() >= 0) and (test_df['target'].max() <= 16),
        'ê²°ì¸¡ì¹˜ ì—†ìŒ': test_df['target'].isnull().sum() == 0,
    }

    all_passed = True
    for check, result in checks.items():
        status = "âœ…" if result else "âŒ"
        print(f"{status} {check}")
        if not result:
            all_passed = False

    if all_passed:
        print("\nğŸ‰ ëª¨ë“  ê²€ì¦ í†µê³¼! ì œì¶œ ê°€ëŠ¥!")
    else:
        print("\nâš ï¸  ë¬¸ì œ ë°œê²¬! ìˆ˜ì • í•„ìš”!")
    
    print()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--exp_dir', type=str, default=None)
    args = parser.parse_args()
    
    main(args.exp_dir)


# 2. ì‹¤í–‰!
