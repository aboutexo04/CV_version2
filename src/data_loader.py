"""
src/data_loader.py
StratifiedGroupKFold (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì—†ìŒ)
"""

import pandas as pd
from torch.utils.data import DataLoader
from sklearn.model_selection import StratifiedGroupKFold

from .dataset import DocumentDataset
from .transforms import get_train_transform, get_val_transform


def _extract_doc_id_column(df: pd.DataFrame):
    """ì´ë¯¸ì§€ IDì—ì„œ ë¬¸ì„œ ID ì¶”ì¶œ"""
    if 'ID' not in df.columns:
        raise ValueError("âŒ train.csvì— 'ID' ì—´ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    # IDì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ doc_id ìƒì„±
    # ì˜ˆ: '002f99746285dfdd.jpg' â†’ '002f99746285dfdd'
    df['doc_id'] = df['ID'].apply(lambda x: str(x).split('.')[0])
    return df


def get_dataloaders(cfg):
    """ë‹¨ì¼ Train/Val DataLoader ìƒì„±"""
    
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ...")
    full_train_df = pd.read_csv(f'{cfg.DATA_DIR}/train.csv')
    
    # ë¬¸ì„œ ID ì¶”ì¶œ
    full_train_df = _extract_doc_id_column(full_train_df)
    
    # StratifiedGroupKFold (ì²« ë²ˆì§¸ foldë§Œ ì‚¬ìš©)
    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=cfg.SEED)
    
    splits = list(sgkf.split(
        full_train_df, 
        full_train_df['target'], 
        groups=full_train_df['doc_id']
    ))
    
    train_idx, val_idx = splits[0]
    
    train_df = full_train_df.iloc[train_idx].reset_index(drop=True)
    val_df = full_train_df.iloc[val_idx].reset_index(drop=True)
    
    print(f"  Train: {len(train_df)}ê°œ ({len(train_df['doc_id'].unique())}ê°œ ë¬¸ì„œ)")
    print(f"  Val: {len(val_df)}ê°œ ({len(val_df['doc_id'].unique())}ê°œ ë¬¸ì„œ)\n")
    
    # Transform
    train_transform = get_train_transform(cfg.IMAGE_SIZE)
    val_transform = get_val_transform(cfg.IMAGE_SIZE)
    
    # Dataset
    train_dataset = DocumentDataset(train_df, cfg.TRAIN_DIR, train_transform)
    val_dataset = DocumentDataset(val_df, cfg.TRAIN_DIR, val_transform)
    
    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=True,
        num_workers=0,
        pin_memory=(cfg.DEVICE.type == 'cuda')
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=(cfg.DEVICE.type == 'cuda')
    )
    
    return train_loader, val_loader


def get_kfold_dataloaders(cfg, fold):
    """K-Fold DataLoader ìƒì„± (StratifiedGroupKFold)"""
    
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë“œ... (Fold {fold+1}/{cfg.N_FOLDS})")
    full_train_df = pd.read_csv(f'{cfg.DATA_DIR}/train.csv')
    
    # ë¬¸ì„œ ID ì¶”ì¶œ
    full_train_df = _extract_doc_id_column(full_train_df)
    
    # StratifiedGroupKFold
    sgkf = StratifiedGroupKFold(
        n_splits=cfg.N_FOLDS, 
        shuffle=True, 
        random_state=cfg.SEED
    )
    
    splits = list(sgkf.split(
        full_train_df,
        full_train_df['target'],
        groups=full_train_df['doc_id']
    ))
    
    train_idx, val_idx = splits[fold]
    
    train_df = full_train_df.iloc[train_idx].reset_index(drop=True)
    val_df = full_train_df.iloc[val_idx].reset_index(drop=True)
    
    print(f"  Train: {len(train_df)}ê°œ ({len(train_df['doc_id'].unique())}ê°œ ë¬¸ì„œ)")
    print(f"  Val: {len(val_df)}ê°œ ({len(val_df['doc_id'].unique())}ê°œ ë¬¸ì„œ)\n")
    
    # Transform
    train_transform = get_train_transform(cfg.IMAGE_SIZE)
    val_transform = get_val_transform(cfg.IMAGE_SIZE)
    
    # Dataset
    train_dataset = DocumentDataset(train_df, cfg.TRAIN_DIR, train_transform)
    val_dataset = DocumentDataset(val_df, cfg.TRAIN_DIR, val_transform)
    
    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=True,
        num_workers=0,
        pin_memory=(cfg.DEVICE.type == 'cuda')
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=(cfg.DEVICE.type == 'cuda')
    )
    
    return train_loader, val_loader