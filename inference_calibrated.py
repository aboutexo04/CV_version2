"""
inference_calibrated.py (ìˆ˜ì •)
"""

import torch
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import numpy as np
import json
from datetime import datetime
import argparse

def main(exp_dir=None):
    from src.config import Config
    from src.transforms import get_val_transform
    from src.dataset import DocumentDataset
    from src.model import get_model
    from torch.utils.data import DataLoader

    cfg = Config()
    device = cfg.DEVICE

    if exp_dir is None:
        exp_dirs = sorted(Path('experiments').glob('exp_*'))
        if not exp_dirs:
            raise ValueError("ì‹¤í—˜ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!")
        exp_dir = exp_dirs[-1]
        print(f"ðŸ“ ê°€ìž¥ ìµœê·¼ ì‹¤í—˜ ì‚¬ìš©: {exp_dir}")
    else:
        exp_dir = Path(exp_dir)

    # ì‹¤í—˜ì˜ ì„¤ì • ë¡œë“œ (results.jsonì—ì„œ)
    results_files = list(exp_dir.glob('results_fold*.json'))
    avg_val_f1 = None

    if results_files:
        # ëª¨ë“  foldì˜ ê²°ê³¼ ë¡œë“œ
        fold_results = []
        for result_file in sorted(results_files):
            with open(result_file, 'r') as f:
                fold_data = json.load(f)
                fold_results.append(fold_data)

        exp_config = fold_results[0]['config']
        model_name = exp_config['model_name']
        image_size = exp_config['image_size']
        dropout = exp_config['dropout']

        # í‰ê·  val F1 ê³„ì‚°
        val_f1_scores = [fold['best_results']['val_f1'] for fold in fold_results]
        avg_val_f1 = np.mean(val_f1_scores)

        print(f"ðŸ“‹ ì‹¤í—˜ ì„¤ì • ë¡œë“œ: {model_name}, img_size={image_size}, dropout={dropout}")
        print(f"ðŸ“Š í‰ê·  Validation F1: {avg_val_f1:.4f}")
    else:
        # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ í˜„ìž¬ config ì‚¬ìš©
        model_name = cfg.MODEL_NAME
        image_size = cfg.IMAGE_SIZE
        dropout = cfg.DROPOUT
        print(f"âš ï¸  ì‹¤í—˜ ì„¤ì • ì—†ìŒ - í˜„ìž¬ config ì‚¬ìš©")

    # K-Fold ëª¨ë¸ í™•ì¸ (ë‘ ê°€ì§€ êµ¬ì¡° ì§€ì›)
    folds_dir = exp_dir / 'folds'
    fold_models = list(exp_dir.glob('best_model_fold*.pth'))

    # folds/ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë˜ëŠ” ì§ì ‘ fold ëª¨ë¸ íŒŒì¼ ì§€ì›
    if folds_dir.exists():
        model_paths = [fold_dir / 'model.pth' for fold_dir in sorted(folds_dir.glob('fold*'))]
    else:
        model_paths = sorted(exp_dir.glob('best_model_fold*.pth'))

    if len(model_paths) == 0:
        raise ValueError("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    print("="*70)
    print("ðŸ”® ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¶”ë¡ ")
    print("="*70)
    print(f"ì‹¤í—˜: {exp_dir.name}")
    print(f"Folds: {len(model_paths)}ê°œ\n")

    # ë°ì´í„° ë¡œë“œ
    test_df = pd.read_csv(f'{cfg.DATA_DIR}/sample_submission.csv')
    print(f"Test: {len(test_df)}ê°œ")

    transform = get_val_transform(image_size)
    test_dataset = DocumentDataset(test_df, cfg.TEST_DIR, transform)
    test_loader = DataLoader(
        test_dataset,
        batch_size=cfg.BATCH_SIZE,
        shuffle=False,
        num_workers=0
    )
    
    # Train ë¶„í¬
    train = pd.read_csv('data/train.csv')
    train_dist = train['target'].value_counts().sort_index().values
    train_dist = train_dist / train_dist.sum()
    
    print("\nðŸ“Š Train ë¶„í¬:")
    for cls in range(17):
        print(f"  í´ëž˜ìŠ¤ {cls:2d}: {train_dist[cls]*100:5.2f}%")
    
    # Foldë³„ ì¶”ë¡ 
    all_predictions = []

    for fold_idx, model_path in enumerate(model_paths):
        print(f"\nðŸ“¦ Fold {fold_idx+1}/{len(model_paths)} ë¡œë“œ...")
        print(f"   {model_path.name}")

        model = get_model(model_name, cfg.NUM_CLASSES, dropout)
        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))
        model = model.to(device)
        model.eval()

        print(f"ðŸ”® Fold {fold_idx+1} ì¶”ë¡  ì¤‘...")
        fold_preds = []

        with torch.no_grad():
            for batch in tqdm(test_loader, desc=f'Fold {fold_idx+1}', leave=False):
                if isinstance(batch, (tuple, list)):
                    images = batch[0]
                else:
                    images = batch

                images = images.to(device)
                outputs = model(images)
                probs = torch.softmax(outputs, dim=1)
                fold_preds.append(probs.cpu().numpy())

        fold_preds = np.concatenate(fold_preds, axis=0)
        all_predictions.append(fold_preds)
        print(f"âœ… Fold {fold_idx+1} ì™„ë£Œ (shape: {fold_preds.shape})")
    
    # ì•™ìƒë¸”
    print("\nðŸ”€ ì•™ìƒë¸” ì¤‘...")
    ensemble_probs = np.mean(all_predictions, axis=0)
    print(f"ì•™ìƒë¸” shape: {ensemble_probs.shape}")
    
    # ì›ë³¸ ì˜ˆì¸¡
    raw_preds = ensemble_probs.argmax(axis=1)
    pred_dist_raw = np.bincount(raw_preds, minlength=17) / len(raw_preds)
    
    print("\nðŸ“Š ì›ë³¸ ì˜ˆì¸¡ ë¶„í¬:")
    for cls in range(17):
        print(f"  í´ëž˜ìŠ¤ {cls:2d}: {pred_dist_raw[cls]*100:5.2f}%")
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜
    print("\nâš™ï¸  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©...")
    
    # ì¡°ì • ê³„ìˆ˜
    calibration = train_dist / (pred_dist_raw + 1e-8)
    calibration = np.clip(calibration, 0.5, 2.0)
    
    print("\nðŸ“ˆ ì¡°ì • ê³„ìˆ˜:")
    for cls in range(17):
        if calibration[cls] > 1.1 or calibration[cls] < 0.9:
            print(f"  í´ëž˜ìŠ¤ {cls:2d}: {calibration[cls]:.2f}x")
    
    # í™•ë¥  ì¡°ì •
    calibrated_probs = ensemble_probs * calibration
    calibrated_probs = calibrated_probs / calibrated_probs.sum(axis=1, keepdims=True)
    
    predictions = calibrated_probs.argmax(axis=1).tolist()

    # ê²°ê³¼ ì €ìž¥ (íŒŒì¼ëª…ì— ë‚ ì§œ, ì‹œê°„, F1 ìŠ¤ì½”ì–´ í¬í•¨)
    test_df['target'] = predictions

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename_parts = [timestamp, f"calibrated_ensemble_{len(model_paths)}fold", model_name]

    if avg_val_f1 is not None:
        filename_parts.append(f"valF1_{avg_val_f1:.4f}")

    submission_filename = "_".join(filename_parts) + ".csv"
    submission_path = exp_dir / submission_filename
    test_df.to_csv(submission_path, index=False)

    print(f"\nâœ… ì €ìž¥: {submission_path}")
    
    # ìµœì¢… ë¶„í¬
    pred_dist_final = np.bincount(predictions, minlength=17) / len(predictions)
    
    print("\nðŸ“Š ìµœì¢… ë¹„êµ:")
    print(f"{'í´ëž˜ìŠ¤':<8} {'Train':<10} {'ì›ë³¸':<10} {'ì¡°ì •í›„':<10}")
    print("-" * 40)
    for cls in range(17):
        print(f"{cls:2d}       {train_dist[cls]*100:5.2f}%    {pred_dist_raw[cls]*100:5.2f}%    {pred_dist_final[cls]*100:5.2f}%")
    
    print("\n" + "="*70)
    print("âœ… ì™„ë£Œ! ì´ íŒŒì¼ì„ ì œì¶œí•˜ì„¸ìš”:")
    print(f"   {submission_path}")
    print("="*70)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--exp_dir', type=str, default=None)
    args = parser.parse_args()

    main(args.exp_dir)